{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626dcbf1",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "Text data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e9ccf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c02f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vijaya/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3dc2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vijaya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51fd705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vijaya/sw_install/anaconda3/envs/nlp/nltk_data.\n",
      "[nltk_data]     ..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c934b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<vijaya & We can combine all the [ preprocessing 9 methods above and create a / preprocess function that takes in a .txt file and handles all the preprocessing. We print out the tokens, filtered words (after stopword filtering), stemmed words, d on to the model or foand POS, one of which is usually passer further processing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3baae354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vijaya   we can combine all the   preprocessing   methods above and create a   preprocess function that takes in a  txt file and handles all the preprocessing  we print out the tokens  filtered words  after stopword filtering   stemmed words  d on to the model or foand pos  one of which is usually passer further processing \n"
     ]
    }
   ],
   "source": [
    "#Removing HTML tags\n",
    "html_tag_remover = re.compile('<.*?>')\n",
    "text = re.sub(html_tag_remover, '', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e17aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vijaya   we can combine all the   preprocessing   methods above and create a   preprocess function that takes in a  txt file and handles all the preprocessing  we print out the tokens  filtered words  after stopword filtering   stemmed words  d on to the model or foand pos  one of which is usually passer further processing \n"
     ]
    }
   ],
   "source": [
    "#Removing non-alphabets(numbers) and convert to lower case\n",
    "text = re.sub('[^a-zA-Z]', ' ', text).lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef6fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vijaya', 'we', 'can', 'combine', 'all', 'the', 'preprocessing', 'methods', 'above', 'and', 'create', 'a', 'preprocess', 'function', 'that', 'takes', 'in', 'a', 'txt', 'file', 'and', 'handles', 'all', 'the', 'preprocessing', 'we', 'print', 'out', 'the', 'tokens', 'filtered', 'words', 'after', 'stopword', 'filtering', 'stemmed', 'words', 'd', 'on', 'to', 'the', 'model', 'or', 'foand', 'pos', 'one', 'of', 'which', 'is', 'usually', 'passer', 'further', 'processing']\n"
     ]
    }
   ],
   "source": [
    "#Performing tokenization\n",
    "words = word_tokenize(text)  # download 'punkt'\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3dd705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vijaya', 'combine', 'preprocessing', 'methods', 'create', 'preprocess', 'function', 'takes', 'txt', 'file', 'handles', 'preprocessing', 'print', 'tokens', 'filtered', 'words', 'stopword', 'filtering', 'stemmed', 'words', 'model', 'foand', 'pos', 'one', 'usually', 'passer', 'processing']\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "words = [word for word in words if word not in stop_words ]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083ca8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vijaya', 'combine', 'preprocessing', 'method', 'create', 'preprocess', 'function', 'take', 'txt', 'file', 'handle', 'preprocessing', 'print', 'token', 'filtered', 'word', 'stopword', 'filtering', 'stemmed', 'word', 'model', 'foand', 'po', 'one', 'usually', 'passer', 'processing']\n"
     ]
    }
   ],
   "source": [
    "#Perform Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = [lemmatizer.lemmatize(word) for word in words]  #download 'wordnet'\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b80032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vijaya', 'combin', 'preprocess', 'method', 'creat', 'preprocess', 'function', 'take', 'txt', 'file', 'handl', 'preprocess', 'print', 'token', 'filter', 'word', 'stopword', 'filter', 'stem', 'word', 'model', 'foand', 'po', 'one', 'usual', 'passer', 'process']\n"
     ]
    }
   ],
   "source": [
    "#Perform Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "words = [porter_stemmer.stem(word) for word in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae7fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vijaya', 'combin', 'preprocess', 'method', 'creat', 'preprocess', 'function', 'take', 'txt', 'file', 'handl', 'preprocess', 'print', 'token', 'filter', 'word', 'stopword', 'filter', 'stem', 'word', 'model', 'foand', 'pos', 'one', 'usual', 'passer', 'process']\n"
     ]
    }
   ],
   "source": [
    "#Snowball stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer(language='english')\n",
    "words = [snow_stemmer.stem(word) for word in words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32e37c",
   "metadata": {},
   "source": [
    "# Feature Extraction / Vectorization\n",
    "\n",
    "Text-to-Numeric : we have diff approaches\n",
    "\n",
    "1. Bag of words (BoW)\n",
    "\n",
    "2. TF-IDF\n",
    "\n",
    "3. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8db2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed8fdd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combin</th>\n",
       "      <th>creat</th>\n",
       "      <th>file</th>\n",
       "      <th>filter</th>\n",
       "      <th>foand</th>\n",
       "      <th>function</th>\n",
       "      <th>handl</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>one</th>\n",
       "      <th>...</th>\n",
       "      <th>print</th>\n",
       "      <th>process</th>\n",
       "      <th>stem</th>\n",
       "      <th>stopword</th>\n",
       "      <th>take</th>\n",
       "      <th>token</th>\n",
       "      <th>txt</th>\n",
       "      <th>usual</th>\n",
       "      <th>vijaya</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   combin  creat  file  filter  foand  function  handl  method  model  one   \n",
       "0       0      0     0       0      0         0      0       0      0    0  \\\n",
       "1       1      0     0       0      0         0      0       0      0    0   \n",
       "2       0      0     0       0      0         0      0       0      0    0   \n",
       "3       0      0     0       0      0         0      0       1      0    0   \n",
       "4       0      1     0       0      0         0      0       0      0    0   \n",
       "\n",
       "   ...  print  process  stem  stopword  take  token  txt  usual  vijaya  word  \n",
       "0  ...      0        0     0         0     0      0    0      0       1     0  \n",
       "1  ...      0        0     0         0     0      0    0      0       0     0  \n",
       "2  ...      0        0     0         0     0      0    0      0       0     0  \n",
       "3  ...      0        0     0         0     0      0    0      0       0     0  \n",
       "4  ...      0        0     0         0     0      0    0      0       0     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOW method\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X = bow_vectorizer.fit_transform(words)\n",
    "\n",
    "bow_df = pd.DataFrame(X.A , columns= bow_vectorizer.get_feature_names_out())\n",
    "bow_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4b0d003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combin</th>\n",
       "      <th>creat</th>\n",
       "      <th>file</th>\n",
       "      <th>filter</th>\n",
       "      <th>foand</th>\n",
       "      <th>function</th>\n",
       "      <th>handl</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>one</th>\n",
       "      <th>...</th>\n",
       "      <th>print</th>\n",
       "      <th>process</th>\n",
       "      <th>stem</th>\n",
       "      <th>stopword</th>\n",
       "      <th>take</th>\n",
       "      <th>token</th>\n",
       "      <th>txt</th>\n",
       "      <th>usual</th>\n",
       "      <th>vijaya</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   combin  creat  file  filter  foand  function  handl  method  model  one   \n",
       "0     0.0    0.0   0.0     0.0    0.0       0.0    0.0     0.0    0.0  0.0  \\\n",
       "1     1.0    0.0   0.0     0.0    0.0       0.0    0.0     0.0    0.0  0.0   \n",
       "\n",
       "   ...  print  process  stem  stopword  take  token  txt  usual  vijaya  word  \n",
       "0  ...    0.0      0.0   0.0       0.0   0.0    0.0  0.0    0.0     1.0   0.0  \n",
       "1  ...    0.0      0.0   0.0       0.0   0.0    0.0  0.0    0.0     0.0   0.0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF method\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(words)\n",
    "\n",
    "tfidf_df = pd.DataFrame(np.round(X.A,3) , columns= tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b170d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
